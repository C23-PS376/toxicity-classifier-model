{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "cxyG9UX0100Y"
      },
      "source": [
        "**Training toxicity classifier model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s4Xiwj4N3vJz"
      },
      "outputs": [],
      "source": [
        "! pip install -q kaggle"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "aB2-QwlO1_lW"
      },
      "source": [
        "Upload kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "xaveEDNz4QnO",
        "outputId": "82110f14-e089-4379-b18a-4b704b062b65"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cibrz4P-4gem"
      },
      "outputs": [],
      "source": [
        "! mkdir ~/.kaggle\n",
        "! cp kaggle.json ~/.kaggle/\n",
        "! chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "p6ryrsSq2GTz"
      },
      "source": [
        "Download dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-9brK8CU5XSD",
        "outputId": "8c084b18-e775-4e5a-e0d7-69754dbcb641"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading jigsaw-toxic-comment-classification-challenge.zip to /content\n",
            " 99% 52.0M/52.6M [00:04<00:00, 15.6MB/s]\n",
            "100% 52.6M/52.6M [00:04<00:00, 12.9MB/s]\n",
            "Archive:  jigsaw-toxic-comment-classification-challenge.zip\n",
            "  inflating: sample_submission.csv.zip  \n",
            "  inflating: test.csv.zip            \n",
            "  inflating: test_labels.csv.zip     \n",
            "  inflating: train.csv.zip           \n"
          ]
        }
      ],
      "source": [
        "! kaggle competitions download -c 'jigsaw-toxic-comment-classification-challenge'\n",
        "! unzip 'jigsaw-toxic-comment-classification-challenge.zip'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "riFRAi-57MkF",
        "outputId": "39721ff5-6212-463c-e84a-499df98edcee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archive:  train.csv.zip\n",
            "  inflating: train.csv               \n",
            "Archive:  test.csv.zip\n",
            "  inflating: test.csv                \n",
            "Archive:  test_labels.csv.zip\n",
            "  inflating: test_labels.csv         \n"
          ]
        }
      ],
      "source": [
        "! unzip 'train.csv.zip'\n",
        "! unzip 'test.csv.zip'\n",
        "! unzip 'test_labels.csv.zip'"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "51WorzPy2Jcs"
      },
      "source": [
        "Download pretrained glove word embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KdRN0nG5Wig7",
        "outputId": "c794651f-cb0b-4924-eb20-f595ddb75c0b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2023-06-03 12:06:24--  https://nlp.stanford.edu/data/glove.twitter.27B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://downloads.cs.stanford.edu/nlp/data/glove.twitter.27B.zip [following]\n",
            "--2023-06-03 12:06:25--  https://downloads.cs.stanford.edu/nlp/data/glove.twitter.27B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1520408563 (1.4G) [application/zip]\n",
            "Saving to: ‘glove.twitter.27B.zip’\n",
            "\n",
            "glove.twitter.27B.z 100%[===================>]   1.42G  5.02MB/s    in 4m 44s  \n",
            "\n",
            "2023-06-03 12:11:10 (5.11 MB/s) - ‘glove.twitter.27B.zip’ saved [1520408563/1520408563]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://nlp.stanford.edu/data/glove.twitter.27B.zip\n",
        "!unzip -q glove.twitter.27B.zip\n",
        "\n",
        "## below is temporary to get embedding from my gdrive\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/gdrive')\n",
        "# ! cp gdrive/MyDrive/glove.twitter.27B.200d.txt glove.twitter.27B.200d.txt "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LT0YqglB7TMM"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import TextVectorization, Embedding\n",
        "from tensorflow.keras import layers"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "WxwA6IFz2Ztr"
      },
      "source": [
        "Load and preprocess dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BnbEBLibWgGc"
      },
      "outputs": [],
      "source": [
        "df_train = pd.read_csv('train.csv')\n",
        "df_test = pd.read_csv('test.csv')\n",
        "df_test_labels = pd.read_csv('test_labels.csv')\n",
        "\n",
        "## combine df_test and its labels then throw away rows with -1 values\n",
        "df_test_labels_normalized = df_test_labels[df_test_labels['toxic']!=-1]\n",
        "df_test_normalized = df_test.set_index('id').join(df_test_labels_normalized.set_index('id'), how='right')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7dRfir_2BRwX"
      },
      "outputs": [],
      "source": [
        "feature = ['comment_text']\n",
        "target = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
        "\n",
        "## convert into tf.data.Dataset\n",
        "train_data = tf.data.Dataset.from_tensor_slices((df_train[feature], df_train[target]))\n",
        "test_data = tf.data.Dataset.from_tensor_slices((\n",
        "    df_test_normalized[feature],\n",
        "    df_test_normalized[target]\n",
        "))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Vx1N9_iM2qFM"
      },
      "source": [
        "Use TextVectorization to convert text to sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "24-cUv-E_dW3"
      },
      "outputs": [],
      "source": [
        "vectorizer = TextVectorization(max_tokens=20000, output_sequence_length=200, ## max_tokens denotes number of words to be tokenized\n",
        "                               pad_to_max_tokens=True)\n",
        "\n",
        "vectorizer.adapt(train_data.map(lambda x, y: x).batch(2000)) ## use .map() to get the input only since in the dataset there are input and label\n",
        "\n",
        "voc = vectorizer.get_vocabulary()\n",
        "word_index = dict(zip(voc, range(len(voc))))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Vfb95fRt2106"
      },
      "source": [
        "Load pretrained word embedding and put it into dictionary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n-UtzzDPBnWd",
        "outputId": "3f9291b2-553d-4cdc-8c47-a0e6d8958cf1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 1193514 word vectors.\n"
          ]
        }
      ],
      "source": [
        "path_to_glove_file = \"glove.twitter.27B.200d.txt\"\n",
        "\n",
        "embeddings_index = {}\n",
        "with open(path_to_glove_file) as f:\n",
        "  for line in f:\n",
        "    word, coefs = line.split(maxsplit=1)\n",
        "    coefs = np.fromstring(coefs, \"f\", sep=\" \")\n",
        "    embeddings_index[word] = coefs\n",
        "\n",
        "print(\"Found %s word vectors.\" % len(embeddings_index))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "yEHcnkzE3HnU"
      },
      "source": [
        "Only use words from pretrained word embedding that exist in vectorizer.get_vocabulary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3lYgicCpCVGN",
        "outputId": "3f0659a6-01f1-4771-a83d-cee5136b9726"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Converted 17856 words (2144 misses)\n"
          ]
        }
      ],
      "source": [
        "num_tokens = len(voc) + 2  ## TextVectorization already includes OOV and padding, but pretrained glove file also includes OOV and padding so we add 2\n",
        "embedding_dim = 200  ## 200 as dimension comes from pretrained word embedding\n",
        "hits = 0\n",
        "misses = 0\n",
        "\n",
        "# Prepare embedding matrix\n",
        "embedding_matrix = np.zeros((num_tokens, embedding_dim))\n",
        "for word, i in word_index.items():\n",
        "  embedding_vector = embeddings_index.get(word)\n",
        "  if embedding_vector is not None:\n",
        "    # Words not found in embedding index will be all-zeros.\n",
        "    # This includes the representation for \"padding\" and \"OOV\"\n",
        "    embedding_matrix[i] = embedding_vector\n",
        "    hits += 1\n",
        "  else:\n",
        "    misses += 1\n",
        "print(\"Converted %d words (%d misses)\" % (hits, misses))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "m6WV-ac53grD"
      },
      "source": [
        "Initialize embedding layer with 20000 of pretrained embedding vectors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mTqKXJUBGKaP"
      },
      "outputs": [],
      "source": [
        "embedding_layer = Embedding(\n",
        "    num_tokens,\n",
        "    embedding_dim,\n",
        "    embeddings_initializer=tf.keras.initializers.Constant(embedding_matrix),\n",
        "    trainable=False,\n",
        ")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "QfDShPDn3oQM"
      },
      "source": [
        "Create sequential model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "73WC8yMbGcWH"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.Sequential([\n",
        "    layers.Input(shape=(200,), dtype='int64'),\n",
        "    embedding_layer,\n",
        "    layers.Bidirectional(layers.GRU(128, return_sequences=False)),\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dense(256, activation='relu'),\n",
        "    layers.Dense(6, activation='sigmoid')\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GXW8hEMpJXBt",
        "outputId": "0a89032e-8183-4029-cd8b-afff325bc2fd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 200, 200)          4000400   \n",
            "                                                                 \n",
            " bidirectional_7 (Bidirectio  (None, 256)              253440    \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " dense_14 (Dense)            (None, 128)               32896     \n",
            "                                                                 \n",
            " dense_15 (Dense)            (None, 256)               33024     \n",
            "                                                                 \n",
            " dense_16 (Dense)            (None, 6)                 1542      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,321,302\n",
            "Trainable params: 320,902\n",
            "Non-trainable params: 4,000,400\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "al4tS0vNstgC"
      },
      "source": [
        "Transform train data and test data from raw text to sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LsgcD8GvKkET"
      },
      "outputs": [],
      "source": [
        "## define function to convert raw text to sequences\n",
        "def to_sequence(x, y):\n",
        "  return vectorizer(x), y\n",
        "\n",
        "## batch, cache, and prefetch\n",
        "## set batch of 512, since we have big vram and so we can better utilize the GPU\n",
        "## batch size tradeoff:\n",
        "## - big batch -> better GPU utilization -> faster training time -> lower accuracy\n",
        "## - small batch -> worse GPU utilization -> slower training time -> higher accuracy\n",
        "train_data = train_data.batch(512).map(to_sequence).cache().prefetch(tf.data.AUTOTUNE) \n",
        "test_data = test_data.batch(512).map(to_sequence).cache().prefetch(tf.data.AUTOTUNE)  "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Zc2WKKyG4T4T"
      },
      "source": [
        "Compile and train model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IuF3BYvgHt_2",
        "outputId": "55bc2be4-8dfd-4f49-ba16-e4b626207fb1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/8\n",
            "312/312 [==============================] - 31s 86ms/step - loss: 0.0911 - recall_4756: 0.4617 - precision_4756: 0.6671 - val_loss: 0.0727 - val_recall_4756: 0.6166 - val_precision_4756: 0.6267\n",
            "Epoch 2/8\n",
            "312/312 [==============================] - 28s 88ms/step - loss: 0.0487 - recall_4756: 0.6608 - precision_4756: 0.8172 - val_loss: 0.0687 - val_recall_4756: 0.6352 - val_precision_4756: 0.6415\n",
            "Epoch 3/8\n",
            "312/312 [==============================] - 26s 82ms/step - loss: 0.0451 - recall_4756: 0.6845 - precision_4756: 0.8250 - val_loss: 0.0655 - val_recall_4756: 0.6541 - val_precision_4756: 0.6559\n",
            "Epoch 4/8\n",
            "312/312 [==============================] - 26s 82ms/step - loss: 0.0427 - recall_4756: 0.7023 - precision_4756: 0.8326 - val_loss: 0.0640 - val_recall_4756: 0.6643 - val_precision_4756: 0.6583\n",
            "Epoch 5/8\n",
            "312/312 [==============================] - 25s 82ms/step - loss: 0.0409 - recall_4756: 0.7149 - precision_4756: 0.8378 - val_loss: 0.0638 - val_recall_4756: 0.6735 - val_precision_4756: 0.6557\n",
            "Epoch 6/8\n",
            "312/312 [==============================] - 27s 87ms/step - loss: 0.0394 - recall_4756: 0.7247 - precision_4756: 0.8405 - val_loss: 0.0637 - val_recall_4756: 0.6749 - val_precision_4756: 0.6582\n",
            "Epoch 7/8\n",
            "312/312 [==============================] - 26s 83ms/step - loss: 0.0380 - recall_4756: 0.7349 - precision_4756: 0.8441 - val_loss: 0.0643 - val_recall_4756: 0.6765 - val_precision_4756: 0.6569\n",
            "Epoch 8/8\n",
            "312/312 [==============================] - 26s 84ms/step - loss: 0.0366 - recall_4756: 0.7447 - precision_4756: 0.8473 - val_loss: 0.0655 - val_recall_4756: 0.6764 - val_precision_4756: 0.6548\n"
          ]
        }
      ],
      "source": [
        "model.compile(loss=tf.keras.losses.BinaryCrossentropy(), \n",
        "              optimizer=tf.keras.optimizers.Adam(learning_rate=0.0006),\n",
        "              metrics=[tf.keras.metrics.Recall(thresholds=0.5),     ## assume the threshold is 0.5\n",
        "                       tf.keras.metrics.Precision(thresholds=0.5)])  ## although it's incorrect, but can give\n",
        "                                                                    ## depiction of training performance\n",
        "history = model.fit(train_data,\n",
        "                    epochs=8, \n",
        "                    validation_data=test_data,\n",
        "                    verbose=1)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "n2pTmXva4qL8"
      },
      "source": [
        "Use greedy search to find out the best threshold that yields the best f1 score for each label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1QG3KC2KE-UT",
        "outputId": "77bfdf4a-88d1-40ff-f6d1-9aa65fc1449d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "312/312 [==============================] - 9s 26ms/step\n",
            "125/125 [==============================] - 3s 26ms/step\n",
            "label:  toxic\n",
            "f1 train:  0.7922951538385359\n",
            "f1 test:  0.7071478879771347\n",
            "threshold:  0.67 \n",
            "\n",
            "label:  severe_toxic\n",
            "f1 train:  0.5312169695572128\n",
            "f1 test:  0.42505590467331844\n",
            "threshold:  0.31 \n",
            "\n",
            "label:  obscene\n",
            "f1 train:  0.8391805388562931\n",
            "f1 test:  0.7001892360513065\n",
            "threshold:  0.47000000000000003 \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-47-73d37a6713ad>:36: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  f1_test = 2 * test_precision * test_recall / (test_precision + test_recall)\n",
            "<ipython-input-47-73d37a6713ad>:35: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  f1_train = 2 * train_precision * train_recall / (train_precision + train_recall)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "label:  threat\n",
            "f1 train:  0.5629053291459745\n",
            "f1 test:  0.5063938579786176\n",
            "threshold:  0.4 \n",
            "\n",
            "label:  insult\n",
            "f1 train:  0.7903103093571139\n",
            "f1 test:  0.6743336770115216\n",
            "threshold:  0.25 \n",
            "\n",
            "label:  identity_hate\n",
            "f1 train:  0.6292880712247115\n",
            "f1 test:  0.5831621893747855\n",
            "threshold:  0.27 \n",
            "\n",
            "average f1 train:  0.6908660619966404\n",
            "average f1 test:  0.5993804588444472\n"
          ]
        }
      ],
      "source": [
        "## make prediction to all train and test dataset\n",
        "train_prediction = model.predict(train_data.map(lambda x, y: x))\n",
        "test_prediction = model.predict(test_data.map(lambda x, y: x))\n",
        "\n",
        "f1_train_scores = []\n",
        "f1_test_scores = []\n",
        "thresholds = []\n",
        "\n",
        "## iterate all 6 labels\n",
        "for idx, tgt in enumerate(target):\n",
        "  best_threshold = 0\n",
        "  max_f1_train = 0\n",
        "  max_f1_test = 0\n",
        "\n",
        "  ## check threshold from 0.01 to 0.99, with 0.01 step\n",
        "  for threshold in np.arange(0.01, 1, 0.01): \n",
        "    train_precision = tf.keras.metrics.Precision(thresholds=threshold)\n",
        "    train_recall = tf.keras.metrics.Recall(thresholds=threshold)\n",
        "    test_precision = tf.keras.metrics.Precision(thresholds=threshold)\n",
        "    test_recall = tf.keras.metrics.Recall(thresholds=threshold)\n",
        "\n",
        "    ## [:, idx] to take slice of 1 label only\n",
        "    ## use data from pandas dataframe since it's not batched\n",
        "    train_precision.update_state(df_train[tgt], train_prediction[:,idx])\n",
        "    train_recall.update_state(df_train[tgt], train_prediction[:,idx])\n",
        "    test_precision.update_state(df_test_normalized[tgt], test_prediction[:,idx])\n",
        "    test_recall.update_state(df_test_normalized[tgt], test_prediction[:,idx])\n",
        "\n",
        "    train_precision = train_precision.result().numpy()\n",
        "    train_recall = train_recall.result().numpy()\n",
        "    test_precision = test_precision.result().numpy()\n",
        "    test_recall = test_recall.result().numpy()\n",
        "\n",
        "    ## get f1 score from train and test data\n",
        "    f1_train = 2 * train_precision * train_recall / (train_precision + train_recall)\n",
        "    f1_test = 2 * test_precision * test_recall / (test_precision + test_recall)\n",
        "\n",
        "    ## get the best f1 score based on test data\n",
        "    if f1_test > max_f1_test:\n",
        "      max_f1_train = f1_train\n",
        "      max_f1_test = f1_test\n",
        "      best_threshold = threshold\n",
        "\n",
        "  print('label: ', tgt)\n",
        "  print('f1 train: ', max_f1_train)\n",
        "  print('f1 test: ', max_f1_test)\n",
        "  print('threshold: ', best_threshold, '\\n')\n",
        "\n",
        "  ## store f1 score of train and test data, also store best threshold\n",
        "  f1_train_scores.append(max_f1_train)\n",
        "  f1_test_scores.append(max_f1_test)\n",
        "  thresholds.append(best_threshold)\n",
        "\n",
        "print('average f1 train: ', np.mean(f1_train_scores))\n",
        "print('average f1 test: ', np.mean(f1_test_scores))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "jM0eQw534cRD"
      },
      "source": [
        "Try predicting with the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XjC3uIYpCJMk",
        "outputId": "d44dc111-4007-4997-f1ee-3b27d3653dad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 24ms/step\n",
            "['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
            "[[ True False False  True False False]]\n",
            "[[0.9833372  0.04298376 0.18612957 0.62194926 0.04752325 0.00073487]]\n"
          ]
        }
      ],
      "source": [
        "np.set_printoptions(precision=8, suppress=True)  ## print in decimal number, not scientific\n",
        "seq = vectorizer([[\"i will smack your face\"]]) ## turn text into sequence first using vectorizer\n",
        "prediction = model.predict(seq)\n",
        "print(target)   ## print all label names\n",
        "print(prediction > thresholds)    ## print prediction values as true or false according to thresholds\n",
        "print(prediction)   ## print prediction value"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "hOOfvR5s5jur"
      },
      "source": [
        "Append TextVectorization layer to the model, so we don't need to do separate preprocessing and can directly input raw text to the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3omGinlDfcWM",
        "outputId": "9ca97b0b-943f-4e46-c428-b8933a9c20be"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " text_vectorization (TextVec  (None, 200)              0         \n",
            " torization)                                                     \n",
            "                                                                 \n",
            " sequential_4 (Sequential)   (None, 6)                 4321302   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,321,302\n",
            "Trainable params: 320,902\n",
            "Non-trainable params: 4,000,400\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Start by creating an explicit input layer. It needs to have a shape of  \n",
        "# (1,) (because we need to guarantee that there is exactly one string  \n",
        "# input per batch), and the dtype needs to be 'string'.\n",
        "end_to_end_model = tf.keras.Sequential([\n",
        "    tf.keras.Input(shape=(1,), dtype=tf.string),\n",
        "    vectorizer,\n",
        "    model\n",
        "])\n",
        "\n",
        "end_to_end_model.summary()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "strGblAb54o9"
      },
      "source": [
        "Try the end-to-end model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bN_hGj4Sf3N2",
        "outputId": "3a34ad8d-cb56-4f5c-fe8c-d7ba7785f1fb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 2s 2s/step\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([[0.9833372 , 0.04298376, 0.18612957, 0.62194926, 0.04752325,\n",
              "        0.00073487]], dtype=float32)"
            ]
          },
          "execution_count": 66,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "end_to_end_model.predict([[\"i will smack your face\"]])  ## can directly input raw text, no need vectorizer"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "52dbGpER6AYj"
      },
      "source": [
        "Save the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n70NcdXEsHYb",
        "outputId": "e2f3b385-40cb-4489-dbc1-76a348a46966"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:absl:Found untraced functions such as gru_cell_22_layer_call_fn, gru_cell_22_layer_call_and_return_conditional_losses, gru_cell_23_layer_call_fn, gru_cell_23_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
          ]
        }
      ],
      "source": [
        "end_to_end_model.save('./saved_model/end-to-end')  ## model with TextVectorization layer"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "nGThNNXe6L6F"
      },
      "source": [
        "Save to google drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GilutX-yxCUz"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "! cp -r saved_model gdrive/MyDrive"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "j1iJuEUI5rXr"
      },
      "source": [
        "Try to load the saved models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C88pWOp1cC1T",
        "outputId": "606c0491-89de-48c8-e465-ff37dd395e47"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
          ]
        }
      ],
      "source": [
        "loaded_end_to_end_model = tf.keras.models.load_model('saved_model/end-to-end')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ZbOMNWzE56DL"
      },
      "source": [
        "Make prediction with loaded models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P30FMnw7c6U0",
        "outputId": "d343ec57-890b-4e54-a096-d82b13b39891"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 1s 685ms/step\n",
            "loaded_end_to_end_model:  [[0.9833372  0.04298376 0.18612957 0.62194926 0.04752325 0.00073487]]\n"
          ]
        }
      ],
      "source": [
        "print('loaded_end_to_end_model: ', loaded_end_to_end_model.predict( [[\"i will smack your face\"]] ))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
