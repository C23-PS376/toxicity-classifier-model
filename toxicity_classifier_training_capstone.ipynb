{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cxyG9UX0100Y"
      },
      "source": [
        "**Training toxicity classifier model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s4Xiwj4N3vJz"
      },
      "outputs": [],
      "source": [
        "! pip install -q kaggle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aB2-QwlO1_lW"
      },
      "source": [
        "Upload kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xaveEDNz4QnO"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cibrz4P-4gem"
      },
      "outputs": [],
      "source": [
        "! mkdir ~/.kaggle\n",
        "! cp kaggle.json ~/.kaggle/\n",
        "! chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p6ryrsSq2GTz"
      },
      "source": [
        "Download dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-9brK8CU5XSD"
      },
      "outputs": [],
      "source": [
        "! kaggle competitions download -c 'jigsaw-toxic-comment-classification-challenge'\n",
        "! unzip 'jigsaw-toxic-comment-classification-challenge.zip'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "riFRAi-57MkF"
      },
      "outputs": [],
      "source": [
        "! unzip 'train.csv.zip'\n",
        "! unzip 'test.csv.zip'\n",
        "! unzip 'test_labels.csv.zip'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "51WorzPy2Jcs"
      },
      "source": [
        "Download pretrained glove word embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KdRN0nG5Wig7",
        "outputId": "893c0ce5-e0ac-4255-b41e-3ca179fbd76a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "!wget https://nlp.stanford.edu/data/glove.twitter.27B.zip\n",
        "!unzip -q glove.twitter.27B.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LT0YqglB7TMM"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import TextVectorization, Embedding\n",
        "from tensorflow.keras import layers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WxwA6IFz2Ztr"
      },
      "source": [
        "Load and preprocess dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BnbEBLibWgGc"
      },
      "outputs": [],
      "source": [
        "df_train = pd.read_csv('train.csv')\n",
        "df_test = pd.read_csv('test.csv')\n",
        "df_test_labels = pd.read_csv('test_labels.csv')\n",
        "\n",
        "## combine df_test and its labels then throw away rows with -1 values\n",
        "df_test_labels_normalized = df_test_labels[df_test_labels['toxic']!=-1]\n",
        "df_test_normalized = df_test.set_index('id').join(df_test_labels_normalized.set_index('id'), how='right')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7dRfir_2BRwX"
      },
      "outputs": [],
      "source": [
        "feature = ['comment_text']\n",
        "target = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
        "\n",
        "## convert into tf.data.Dataset\n",
        "train_data = tf.data.Dataset.from_tensor_slices((df_train[feature], df_train[target]))\n",
        "test_data = tf.data.Dataset.from_tensor_slices((\n",
        "    df_test_normalized[feature],\n",
        "    df_test_normalized[target]\n",
        "))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vx1N9_iM2qFM"
      },
      "source": [
        "Use TextVectorization to convert text to sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "24-cUv-E_dW3"
      },
      "outputs": [],
      "source": [
        "vectorizer = TextVectorization(max_tokens=20000, output_sequence_length=200, ## max_tokens denotes number of words to be tokenized\n",
        "                               pad_to_max_tokens=True)\n",
        "\n",
        "vectorizer.adapt(train_data.map(lambda x, y: x).batch(2000)) ## use .map() to get the input only since in the dataset there are input and label\n",
        "\n",
        "voc = vectorizer.get_vocabulary()\n",
        "word_index = dict(zip(voc, range(len(voc))))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vfb95fRt2106"
      },
      "source": [
        "Load pretrained word embedding and put it into dictionary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n-UtzzDPBnWd"
      },
      "outputs": [],
      "source": [
        "path_to_glove_file = \"glove.twitter.27B.200d.txt\"\n",
        "\n",
        "embeddings_index = {}\n",
        "with open(path_to_glove_file) as f:\n",
        "  for line in f:\n",
        "    word, coefs = line.split(maxsplit=1)\n",
        "    coefs = np.fromstring(coefs, \"f\", sep=\" \")\n",
        "    embeddings_index[word] = coefs\n",
        "\n",
        "print(\"Found %s word vectors.\" % len(embeddings_index))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yEHcnkzE3HnU"
      },
      "source": [
        "Only use words from pretrained word embedding that exist in vectorizer.get_vocabulary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3lYgicCpCVGN"
      },
      "outputs": [],
      "source": [
        "num_tokens = len(voc) + 2  ## TextVectorization already includes OOV and padding, but pretrained glove file also includes OOV and padding so we add 2\n",
        "embedding_dim = 200  ## 200 as dimension comes from pretrained word embedding\n",
        "hits = 0\n",
        "misses = 0\n",
        "\n",
        "# Prepare embedding matrix\n",
        "embedding_matrix = np.zeros((num_tokens, embedding_dim))\n",
        "for word, i in word_index.items():\n",
        "  embedding_vector = embeddings_index.get(word)\n",
        "  if embedding_vector is not None:\n",
        "    # Words not found in embedding index will be all-zeros.\n",
        "    # This includes the representation for \"padding\" and \"OOV\"\n",
        "    embedding_matrix[i] = embedding_vector\n",
        "    hits += 1\n",
        "  else:\n",
        "    misses += 1\n",
        "print(\"Converted %d words (%d misses)\" % (hits, misses))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m6WV-ac53grD"
      },
      "source": [
        "Initialize embedding layer with 20000 of pretrained embedding vectors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mTqKXJUBGKaP"
      },
      "outputs": [],
      "source": [
        "embedding_layer = Embedding(\n",
        "    num_tokens,\n",
        "    embedding_dim,\n",
        "    embeddings_initializer=tf.keras.initializers.Constant(embedding_matrix),\n",
        "    trainable=False,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QfDShPDn3oQM"
      },
      "source": [
        "Create sequential model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "73WC8yMbGcWH"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.Sequential([\n",
        "    layers.Input(shape=(200,), dtype='int64'),\n",
        "    embedding_layer,\n",
        "    layers.Bidirectional(layers.GRU(128, return_sequences=False)),\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dense(256, activation='relu'),\n",
        "    layers.Dense(6, activation='sigmoid')\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GXW8hEMpJXBt"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "al4tS0vNstgC"
      },
      "source": [
        "Transform train data and test data from raw text to sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LsgcD8GvKkET"
      },
      "outputs": [],
      "source": [
        "## define function to convert raw text to sequences\n",
        "def to_sequence(x, y):\n",
        "  return vectorizer(x), y\n",
        "\n",
        "## batch, cache, and prefetch\n",
        "## set batch of 512, since we have big vram and so we can better utilize the GPU\n",
        "## batch size tradeoff:\n",
        "## - big batch -> better GPU utilization -> faster training time -> lower accuracy\n",
        "## - small batch -> worse GPU utilization -> slower training time -> higher accuracy\n",
        "train_data = train_data.batch(512).map(to_sequence).cache().prefetch(tf.data.AUTOTUNE) \n",
        "test_data = test_data.batch(512).map(to_sequence).cache().prefetch(tf.data.AUTOTUNE)  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zc2WKKyG4T4T"
      },
      "source": [
        "Compile and train model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IuF3BYvgHt_2"
      },
      "outputs": [],
      "source": [
        "model.compile(loss=tf.keras.losses.BinaryCrossentropy(), \n",
        "              optimizer=tf.keras.optimizers.Adam(learning_rate=0.0006),\n",
        "              metrics=[tf.keras.metrics.BinaryAccuracy()]) \n",
        "                                                                  \n",
        "history = model.fit(train_data,\n",
        "                    epochs=8, \n",
        "                    validation_data=test_data,\n",
        "                    verbose=1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n2pTmXva4qL8"
      },
      "source": [
        "Use greedy search to find out the best threshold that yields the best accuracy for each label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NMNN_4TaGfgn"
      },
      "outputs": [],
      "source": [
        "## make prediction to all train and test dataset\n",
        "train_prediction = model.predict(train_data.map(lambda x, y: x))\n",
        "test_prediction = model.predict(test_data.map(lambda x, y: x))\n",
        "\n",
        "train_accuracy_scores = []\n",
        "test_accuracy_scores = []\n",
        "thresholds = []\n",
        "\n",
        "## iterate all 6 labels\n",
        "for idx, tgt in enumerate(target):\n",
        "  best_threshold = 0\n",
        "  max_train_accuracy = 0\n",
        "  max_test_accuracy = 0\n",
        "\n",
        "  ## check threshold from 0.01 to 0.99, with 0.01 step\n",
        "  for threshold in np.arange(0.01, 1, 0.01): \n",
        "    train_accuracy = tf.keras.metrics.BinaryAccuracy(threshold=threshold)\n",
        "    test_accuracy = tf.keras.metrics.BinaryAccuracy(threshold=threshold)\n",
        "\n",
        "    ## [:, idx] to take slice of 1 label only\n",
        "    ## use data from pandas dataframe since it's not batched\n",
        "    train_accuracy.update_state(df_train[tgt], train_prediction[:,idx])\n",
        "    test_accuracy.update_state(df_test_normalized[tgt], test_prediction[:,idx])\n",
        "\n",
        "    train_accuracy = train_accuracy.result().numpy()\n",
        "    test_accuracy = test_accuracy.result().numpy()\n",
        "\n",
        "    ## get the best accuracy score based on train data\n",
        "    if train_accuracy > max_train_accuracy:\n",
        "      max_test_accuracy = test_accuracy\n",
        "      max_train_accuracy = train_accuracy\n",
        "      best_threshold = threshold\n",
        "\n",
        "  print('label: ', tgt)\n",
        "  print('train_accuracy: ', train_accuracy)\n",
        "  print('test_accuracy: ', test_accuracy)\n",
        "  print('threshold: ', best_threshold, '\\n')\n",
        "\n",
        "  ## store f1 score of train and test data, also store best threshold\n",
        "  train_accuracy_scores.append(train_accuracy)\n",
        "  test_accuracy_scores.append(test_accuracy)\n",
        "  thresholds.append(best_threshold)\n",
        "\n",
        "print('average train accuracy: ', np.mean(train_accuracy_scores))\n",
        "print('average test accuracy: ', np.mean(test_accuracy_scores))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jM0eQw534cRD"
      },
      "source": [
        "Try predicting with the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XjC3uIYpCJMk"
      },
      "outputs": [],
      "source": [
        "np.set_printoptions(precision=8, suppress=True)  ## print in decimal number, not scientific\n",
        "seq = vectorizer([[\"nigga\"]]) ## turn text into sequence first using vectorizer\n",
        "prediction = model.predict(seq)\n",
        "print(target)   ## print all label names\n",
        "print(prediction > thresholds)    ## print prediction values as true or false according to thresholds\n",
        "print(prediction)   ## print prediction value"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hOOfvR5s5jur"
      },
      "source": [
        "Append TextVectorization layer to the model, so we don't need to do separate preprocessing and can directly input raw text to the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3omGinlDfcWM"
      },
      "outputs": [],
      "source": [
        "# Start by creating an explicit input layer. It needs to have a shape of  \n",
        "# (1,) (because we need to guarantee that there is exactly one string  \n",
        "# input per batch), and the dtype needs to be 'string'.\n",
        "end_to_end_model = tf.keras.Sequential([\n",
        "    tf.keras.Input(shape=(1,), dtype=tf.string),\n",
        "    vectorizer,\n",
        "    model\n",
        "])\n",
        "\n",
        "end_to_end_model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "strGblAb54o9"
      },
      "source": [
        "Try the end-to-end model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bN_hGj4Sf3N2"
      },
      "outputs": [],
      "source": [
        "end_to_end_model.predict([[\"i will smack your face\"]])  ## can directly input raw text, no need vectorizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "52dbGpER6AYj"
      },
      "source": [
        "Save the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n70NcdXEsHYb"
      },
      "outputs": [],
      "source": [
        "end_to_end_model.save('./saved_model/end-to-end')  ## model with TextVectorization layer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nGThNNXe6L6F"
      },
      "source": [
        "Save to google drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GilutX-yxCUz"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/gdrive')\n",
        "# ! cp -r saved_model gdrive/MyDrive"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PzDcLSVtDFjU"
      },
      "source": [
        "Load from google drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P-bHCsl5DE_s"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "! cp -r gdrive/MyDrive/saved_model saved_model "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j1iJuEUI5rXr"
      },
      "source": [
        "Try to load the saved models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C88pWOp1cC1T"
      },
      "outputs": [],
      "source": [
        "loaded_end_to_end_model = tf.keras.models.load_model('saved_model/end-to-end')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZbOMNWzE56DL"
      },
      "source": [
        "Make prediction with loaded models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P30FMnw7c6U0"
      },
      "outputs": [],
      "source": [
        "print('loaded_end_to_end_model: ', loaded_end_to_end_model.predict( [[\"i will smack your face\"]] ))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
